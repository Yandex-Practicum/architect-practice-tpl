# Технический проект "Сервис отправки оповещений"

> Это фрагмент Технического проекта, который нужно заполнить в рамках практического задания темы "Технический проект".
---

## Текущая архитектура

В текущей архитектуре у нас есть мобильное приложение, которое общается с компонентом "Controller", а он в свою очередь
делает запросы к "Foo" и "Bar".

Примерная оценка параметров:

- RPS (запросов в секунду): Для оценки RPS необходимо знать ожидаемую нагрузку на систему. Приближенно можно оценить RPS
  для каждого канала связи. Например, пусть, количество оповещений в секунду составляет 1000 RPS.

- Место (байт): Для оценки места необходимо знать размер данных, которые будут передаваться в каждом оповещении. Возьмем
  среднее значение 1 КБ.

- Бесперебойная работа (uptime): Для оценки бесперебойной работы необходимо определить SLA (Service Level Agreement) или
  требования к доступности системы. Например, требуется достичь 99.99% доступности.

Подведем подсчёты(Все расчёты приблизительные!):

- Общий размер запросов в секунду:
  1000 RPS * 1 КБ = 1000 КБ/сек (или 1 МБ/сек)

- Общий размер запросов в день:
  1000 КБ/сек * 60 сек * 60 мин * 24 часа = 86 400 000 КБ (или 86 400 МБ, или 86.4 ГБ)

Для хранения всех 1000 запросов в секунду в течение 24 часов потребуется хранилище примерно размером 86.4 ГБ в день.

Так же для достижения 99.99% доступности в месяц, допустимое время простоя составит 0.01% * 30 дней * 24 часа * 60
минут = 43.2 минуты.

----

![alt text](static/current_arch.svg)

## Целевая архитектура

### Диаграмма контекста (C1):

![C1](static/c1.svg)

Предполагается, что любой из существующих компонентов может отправить оповещение пользователю. При этом существующие
каналы связи и предпочтения по их использованию известны системе оповещений, компоненты остальной системы знать это не
должны.

### Диаграмма контекста (C2):

![C2](static/с2.svg)

При анализе расчётов по кол-ву RPC, а так же доступности нашего приложения, было принято решение выбрать путь микросервисной(МКС)
архитектуры(https://learn.microsoft.com/en-us/dotnet/architecture/microservices/architect-microservice-container-applications/microservices-architecture).
В случае разделения приложения на части, у нас появится возможность в масштабировании отдельных(узких) мест или всего приложения.
подробней([ADR-001](static/adr/adr-001.md))

Приложение будет разбито на несколько сервисов

- Основной сервис(Controller). Здесь происходит вся основная логика обработки сообщений(идентификация, шаблонизация,
  удаление дублей).


- Сервис пользовательской конфигурации(Configuration service). Было принято решение вынести сервис конфигураций настроек
  пользователей отдельно, благодаря этому
  мы сможем масштабировать его отдельно от других компонентов системы.


- Слой предварительной обработки сообщений(Middleware System). Перед попаданием сообщений в нашу первичную очередь,
  необходимо валидировать данные(схему)
  за это будет отвечать небольшой сервис реализованный на любом языке, в подробности не вдавался, так как тут можно
  сделать что угодно, но так как все остальное у нас на java,
  думаю этот сервис так же нужно будет реализовать на java.


- База данных(База данных).В качестве БД выбрана PostgresQL, реляционная база данных нам нужна для необходимых выборок
  из данных по
  условиям(лимиты, сервисы, пользователи, флаги активации сообщений), что отлично ложится на таблицы,
  не знаю на сколько будет качественное шардирование базы, потому что оно увеличит сложность поддержки системы
  многократно,
  предлагаю пока обойтись дополнительными репликами для чтения, а если уже и запись возрастет, тогда и подумать над
  шардированием.


- Брокер сообщений(Message broker). Наша система планирует быть высоконагруженной и нам важна сохранность сообщений,
  масштабируемость и при необходимости распределенность системы сообщений, плюс брокер должен уметь делать не только
  push,
  но и работать с pull запросами по паттерну Polling
  Consumer(https://www.enterpriseintegrationpatterns.com/patterns/messaging/PollingConsumer.html),
  выбор был сделан в сторону ActiveMQ, подробней([ADR-002](static/adr/adr-002.md))


- Система аутентификации, авторизации(Authentication System). Все запросы ко всем компонентам должны быть защищены.
  Чтобы не создавать свой сервис для авторизации, есть возможность использовать готовое решение Keycloak,
  инструмент с открытым кодом, многим знаком и многие его используют, подробней([ADR-002](static/adr/adr-003.md))

----

### Диаграмма контекста (C3):

**Controller**

![C3](static/с3.svg)

Внешние системы должны регистрировать себя в приложении уведомлений, так же после регистрации добавлять своих
пользователей в систему для
будущей выборки по отправке сообщений(Чтобы другие пользователи не получали лишних уведомлений)
Внешней системе так же доступна настройка(включение/отключение) видов уведомлений которые она предоставляет(Смс, email,
push) их количество(Если есть ограничение по кол-ву).

После регистрации, внешняя система может получить необходимые схемы в формате JSON, для разных уведомлений.

Добавлен API администратора, сервису нужен контроль со стороны. Для загрузки и редактирования шаблонов сообщений(JSON
Schema) и управление приложением.
В частности частота отправки различных уведомлений, максимальное количество уведомлений.

Все сообщения обрабатываются в зависимости от правил шаблонов(Смс, email, push).

Предусмотренно два обменника, один для необработанных сообщений(сторонние системы),
второй для форматированных сообщений по шаблонам, подготовленных к отправке в сервисы уведомлений.

-----
**Notification system**

![C3](static/C3_notify.svg)

Отправка осуществляется 3мя компонентами, которые при необходимости можно масштабировать раздельно.

-----

**Message broker**

![C3](static/С3_message_broker.svg)

Все очереди сообщений устроены одинаково.

- Отправка сообщения
- При неудаче, повторная отправке сообщения с постоянно увеличивающейся задержкой
- После 3-х попыток сообщение отправляется в базу данных

Сообщения в базе делятся на те которые можно повторно отправить(Если ошибка в принимающей стороне)
и те которые не возможно отправить вновь(остальные ошибки)

---- 

***Инфраструктура***

1. Nginx балансировщик: Для обеспечения распределения нагрузки и улучшения отказоустойчивости, Nginx обладает высокой
   производительностью и способен эффективно распределять запросы между несколькими серверами приложений.
   Это позволяет обеспечить стабильную работу приложения даже при большом количестве одновременных запросов.


2. Kubernetes (k8s): Для управления и оркестрации приложениями,
   Kubernetes обеспечивает автоматическое масштабирование, управление ресурсами и высокую доступность приложений.
   Также обладает широким набором инструментов для мониторинга.


3. GitLab CI/CD - Для непрерывной интеграции и доставки (CI/CD), альтернатив несколько, так как сейчас нет команды, я
   выбрал на своё усмотрение

Видел использование nginx + spring cloud api gateway(с автоматическим обнаружением сервисов) + kubernetes, но не
понравилось
что небольшая инфраструктурная часть ушла в код приложений. В нашем случае проксированием и обнаружением будет
заниматься nginx так как с этим инструментом
проще найти человека в команду(Исходя из оставляемых резюме на hh.ru).

----

***Прототип***

***Что предстоит проверить***

1. Удобство апи для взаимодействия со сторонними системами.

2. Безопасность пользовательских данных поступивших от внешних систем

3. Надежность системы

   3.1 Нужно ли хранить историю сообщения

   3.2 Сохранность поступивших сообщений при сбое

4. На сколько велика задержка отправки push уведомлений, при сборе их в пачку(Лимиты)

5. Проверить интеграции с различными провайдерам, email, sms, push. Скорость обработки, возможность масштабирования(По
   этому поводу нужен анализ провайдеров предоставляющих услуги, может занять большое кол-во времени)

Для прототипа мы можем урезать несколько компонентов, таких как:

- Компонент удаление дублей
- Компонент проверки шаблона сообщений
- Keycloak для прототипа заменить на spring security
- Объединить все оставшиеся сервисы в один монолит для простоты правок и развертывания

В прототипе мы не можем отказаться от очередей, так как нам нужно провести нагрузочное тестирование
для определения узких мест которые мы в дальнейшем сможем разбить на отдельные микросервисы, для масштабирования только
необходимой части.
И так же для внесения дополнительных правок в архитектуру проекта.

По итогам теста прототипа по пунктам 3.1, 3.2, а так же если нам понадобится аналитика, можно будет подумать насчет
замены брокера на распределенный лог
Kafka(https://www.baeldung.com/apache-activemq-vs-kafka) с ее инфраструктурой Kafka Connect, Kafka Streams для анализа
данных.
Соответственно и с расходом дополнительных ресурсов на развертывание.

----

***Стек технологий***

Здесь все по канонам java бэкенд разработки, Spring boot, activeMQ, postgreSQl,
Keycloak, все инструменты отлично сочетаются друг с другом, огромный пласт поддержки в виде дополнительных библиотек
и обширного комьюнити. Так же на этот стек проще всего найти квалифицированных разработчиков в силу зрелости
инструментов.


